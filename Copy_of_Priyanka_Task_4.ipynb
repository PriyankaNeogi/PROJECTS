{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOc1Nijdqmg5",
        "outputId": "7f081161-eb3f-441c-e033-824a2abccb67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: MTCNN in /usr/local/lib/python3.10/dist-packages (0.1.1)\n",
            "Requirement already satisfied: keras>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from MTCNN) (2.12.0)\n",
            "Requirement already satisfied: opencv-python>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from MTCNN) (4.7.0.72)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python>=4.1.0->MTCNN) (1.22.4)\n"
          ]
        }
      ],
      "source": [
        "pip install MTCNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToGA1fTiqdLA"
      },
      "outputs": [],
      "source": [
        "# face detection with mtcnn on a photograph\n",
        "from matplotlib import pyplot\n",
        "from mtcnn import MTCNN\n",
        "import imutils\n",
        "from imutils import face_utils\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import cv2\n",
        "import dlib\n",
        "detector = MTCNN()\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezDPcoPOqdOB"
      },
      "outputs": [],
      "source": [
        "class FaceAligner:\n",
        "    #modify the box size with changing the values for desiredLeftEye\n",
        "    def __init__(self, desiredLeftEye=(0.30, 0.30),\n",
        "        desiredFaceWidth=224, desiredFaceHeight=None):\n",
        "        # store the facial landmark predictor, desired output left\n",
        "        # eye position, and desired output face width + height\n",
        "        self.desiredLeftEye = desiredLeftEye\n",
        "        self.desiredFaceWidth = desiredFaceWidth\n",
        "        self.desiredFaceHeight = desiredFaceHeight\n",
        "        # if the desired face height is None, set it to be the\n",
        "        # desired face width (normal behavior)\n",
        "        if self.desiredFaceHeight is None:\n",
        "            self.desiredFaceHeight = self.desiredFaceWidth\n",
        "    def align(self, image, left_eye, right_eye):\n",
        "\n",
        "        # compute the angle between the eye centroids\n",
        "        dY = right_eye[1] - left_eye[1]\n",
        "        dX = right_eye[0] - left_eye[0]\n",
        "        angle = np.degrees(np.arctan2(dY, dX))\n",
        "\n",
        "        #compute the desired right eye x-coordinate based on the\n",
        "        # desired x-coordinate of the left eye\n",
        "        desiredRightEyeX = 1.0 - self.desiredLeftEye[0]\n",
        "\n",
        "        # determine the scale of the new resulting image by taking\n",
        "        # the ratio of the distance between eyes in the *current*\n",
        "        # image to the ratio of distance between eyes in the\n",
        "        # *desired* image\n",
        "        dist = np.sqrt((dX ** 2) + (dY ** 2))\n",
        "        desiredDist = (desiredRightEyeX - self.desiredLeftEye[0])\n",
        "        desiredDist *= self.desiredFaceWidth\n",
        "        scale = desiredDist / dist\n",
        "\n",
        "        # compute center (x, y)-coordinates (i.e., the median point)\n",
        "        # between the two eyes in the input image\n",
        "        eyesCenter = (int((left_eye[0] + right_eye[0]) // 2),\n",
        "                      int((left_eye[1] + right_eye[1]) // 2))\n",
        "        # grab the rotation matrix for rotating and scaling the face\n",
        "        #print(eyesCenter,angle,scale)\n",
        "        M = cv2.getRotationMatrix2D(eyesCenter, angle, scale)\n",
        "        # update the translation component of the matrix\n",
        "        tX = self.desiredFaceWidth * 0.5\n",
        "        tY = self.desiredFaceHeight * self.desiredLeftEye[1]\n",
        "        M[0, 2] += (tX - eyesCenter[0])\n",
        "        M[1, 2] += (tY - eyesCenter[1])\n",
        "\n",
        "        # apply the affine transformation\n",
        "        (w, h) = (self.desiredFaceWidth, self.desiredFaceHeight)\n",
        "        output = cv2.warpAffine(image, M, (w, h),flags=cv2.INTER_CUBIC)\n",
        "        # return the aligned face\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tcqxlE1qtITe"
      },
      "outputs": [],
      "source": [
        "def detect_face(img_path):\n",
        "    image = cv2.imread(img_path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    conv_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "    face_detect = dlib.get_frontal_face_detector()\n",
        "    dect = face_detect(conv_gray,1)\n",
        "    print(\"The number of faces in the image are :\", len(dect),\"\\nCoordinates of top left and right bottom corner \",dect)\n",
        "\n",
        "\n",
        "    for (i, dect) in enumerate(dect):\n",
        "        (x, y, w, h) = face_utils.rect_to_bb(dect)\n",
        "        cv2.rectangle(image, (x, y), (x + w, y + h), (210,210,0), 6)\n",
        "\n",
        "\n",
        "    plt.imshow(image)\n",
        "    plt.show()\n",
        "    print(\"_________________________________________________________\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1slapgvUqdQo"
      },
      "outputs": [],
      "source": [
        "def detect_face1(img):\n",
        "    pixels = pyplot.imread(img)\n",
        "\n",
        "    faces = detector.detect_faces(pixels)\n",
        "    #print(faces)\n",
        "    return faces"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGzEABG4qdYu"
      },
      "outputs": [],
      "source": [
        "img = 'group.jpg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Br9n-PxsqdgQ"
      },
      "outputs": [],
      "source": [
        "#  # Dimension of extracted data\n",
        "# for i in range(0,len(faces)):\n",
        "#   print(data[\"encodings\"][i].shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7RC6C71Twtv2"
      },
      "source": [
        "* Total 128 dimensions extracted in embedding of an image."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fdxozSrW11mU"
      },
      "outputs": [],
      "source": [
        "# common\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from IPython.display import clear_output as cls\n",
        "\n",
        "# Data\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Model\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y_O2lsITxEUr",
        "outputId": "4f5264ba-137f-4b8d-d298-e157c1b216b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "unzip:  cannot find or open file.zip, file.zip.zip or file.zip.ZIP.\n"
          ]
        }
      ],
      "source": [
        "!unzip file.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LjldQfeJzQ21",
        "outputId": "6a5dee49-3eca-42e8-a3ce-f8e6153bdf45"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "file_name = 'cropped.zip'\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jzj__-skz159"
      },
      "outputs": [],
      "source": [
        "# ROOT DIR\n",
        "ROOT_PATH = 'cropped'\n",
        "\n",
        "# Class names\n",
        "CLASS_NAMES = sorted(os.listdir(ROOT_PATH))\n",
        "\n",
        "# Image Size\n",
        "IMAGE_HEIGHT, IMAGE_WIDTH = 160, 160\n",
        "IMAGE_SIZE = (IMAGE_WIDTH, IMAGE_HEIGHT, 3)\n",
        "\n",
        "# Random Seed\n",
        "np.random.seed(42)\n",
        "tf.random.set_seed(42)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install face_recognition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDZPOjUY_NWZ",
        "outputId": "5d7869af-78cb-4235-a325-0a150901ba85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: face_recognition in /usr/local/lib/python3.10/dist-packages (1.3.0)\n",
            "Requirement already satisfied: face-recognition-models>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (0.3.0)\n",
            "Requirement already satisfied: Click>=6.0 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.1.3)\n",
            "Requirement already satisfied: dlib>=19.7 in /usr/local/lib/python3.10/dist-packages (from face_recognition) (19.24.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from face_recognition) (1.22.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from face_recognition) (8.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "7jI7GQciadU5",
        "outputId": "32a14525-cc6a-4702-9022-c1d55738d2c6"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-00c4d909d8d9>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mimutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mface_recognition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/face_recognition/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__version__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'1.2.3'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mapi\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_image_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_face_locations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_landmarks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_encodings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompare_faces\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mface_distance\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/face_recognition/api.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mcnn_face_detection_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detector_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mcnn_face_detector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcnn_face_detection_model_v1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnn_face_detection_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mface_recognition_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mface_recognition_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mface_recognition_model_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Error while calling cudaGetDevice(&the_device_id) in file /tmp/pip-install-70i9v2xc/dlib_f6f6b3607ed04561a576a7a991f26a15/dlib/cuda/gpu_data.cpp:204. code: 35, reason: CUDA driver version is insufficient for CUDA runtime version"
          ]
        }
      ],
      "source": [
        "from imutils import paths\n",
        "import face_recognition\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "#get paths of each file in folder named Images\n",
        "#Images here contains my data(folders of various persons)\n",
        "imagePaths = list(paths.list_images('cropped'))\n",
        "knownEncodings = []\n",
        "knownNames = []\n",
        "\n",
        "# loop over the image paths\n",
        "for imagePath in imagePaths:\n",
        "    # extract the person name from the image path\n",
        "    name = imagePath.split('/')[-1]\n",
        "    # load the input image and convert it from BGR (OpenCV ordering)\n",
        "    # to dlib ordering (RGB)\n",
        "    image = cv2.imread(imagePath)\n",
        "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    #Use Face_recognition to locate faces\n",
        "    boxes = face_recognition.face_locations(rgb,model='hog')\n",
        "    # compute the facial embedding for the face\n",
        "    encodings = face_recognition.face_encodings(rgb, boxes)\n",
        "    # known_Encodings.append(encodings)\n",
        "\n",
        "    # print(type(encodings))\n",
        "    knownEncodings.append(encodings)\n",
        "    knownNames.append(name)\n",
        "print(knownEncodings)\n",
        "print(knownNames)\n",
        "\n",
        "#save emcodings along with their names in dictionary data\n",
        "    #\n",
        "#use pickle to save data into a file for later use\n",
        "# print(data)\n",
        "# f = open(\"face_enc\", \"wb\")\n",
        "# f.write(pickle.dumps(data))\n",
        "# f.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FFF8rj2dqdd6"
      },
      "outputs": [],
      "source": [
        "fa = FaceAligner(desiredFaceWidth=224)  # Calling the FaceAligner function\n",
        "original_img= cv2.imread(img)           # Reads the image\n",
        "print(\"Original face\")\n",
        "plt.imshow(original_img[:, :, ::-1])    # Displays the image\n",
        "plt.show()\n",
        "\n",
        "!mkdir Faces1\n",
        "faces = detect_face1(img)                # Calls the function to display image\n",
        "detect_face(img)\n",
        "\n",
        "if len(faces)>0:                        # Calculates the number of faces\n",
        "      i=0\n",
        "      #print(faces)\n",
        "      for face in faces:\n",
        "            aligned_img = fa.align(cv2.imread(img), face['keypoints']['left_eye'], face['keypoints']['right_eye'])\n",
        "\n",
        "            print(\"Aligned face: {}, Accuracy: {:.3f}\".format(i+1, face['confidence']*100))\n",
        "            plt.imshow(aligned_img[:, :, ::-1])\n",
        "            plt.show()\n",
        "            image_name = 'image'+str(i+1)+'.jpg'\n",
        "            image_path = os.path.join('/content/Faces1',image_name)\n",
        "            cv2.imwrite(image_path,aligned_img[:, :, ::-1])\n",
        "            i+=1\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "49VZiQv6X0Gp"
      },
      "outputs": [],
      "source": [
        "from imutils import paths\n",
        "import face_recognition\n",
        "import pickle\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "\n",
        "#get paths of each file in folder named Images\n",
        "#Images here contains my data(folders of various persons)\n",
        "imagePaths = list(paths.list_images('Faces1'))\n",
        "CropEncodings = []\n",
        "knownNames1 = []\n",
        "\n",
        "# loop over the image paths\n",
        "for imagePath in imagePaths:\n",
        "    # extract the person name from the image path\n",
        "    name = imagePath.split('/')[-1]\n",
        "    # load the input image and convert it from BGR (OpenCV ordering)\n",
        "    # to dlib ordering (RGB)\n",
        "    image = cv2.imread(imagePath)\n",
        "    rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    #Use Face_recognition to locate faces\n",
        "    boxes = face_recognition.face_locations(rgb,model='hog')\n",
        "    # compute the facial embedding for the face\n",
        "    crop_enc = face_recognition.face_encodings(rgb, boxes)\n",
        "\n",
        "    # loop over the encodings\n",
        "\n",
        "    CropEncodings.append(crop_enc)\n",
        "print(CropEncodings)\n",
        "#save emcodings along with their names in dictionary data\n",
        "    # data1 = {\"encodings\": knownEncodings1}\n",
        "#use pickle to save data into a file for later use\n",
        "# print(data)\n",
        "# f = open(\"face_enc\", \"wb\")\n",
        "# f.write(pickle.dumps(data))\n",
        "# f.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# knownEncodings\n",
        "# knownNames\n",
        "# CropEncodings"
      ],
      "metadata": {
        "id": "DT1-i0qP80sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val = []\n",
        "for i in range(0, len(knownNames)):\n",
        "\n",
        "  for j in range(0, len(knownNames)):\n",
        "\n",
        "    results = face_recognition.compare_faces([knownEncodings[i][0]], CropEncodings[j][0])\n",
        "\n",
        "    if results[0] == True:\n",
        "      val.append(i)\n",
        "      print(\"It's a match!\")\n",
        "\n",
        "    else:\n",
        "\n",
        "      print(\"It's not a match!\")\n",
        "\n",
        "print(val)"
      ],
      "metadata": {
        "id": "p2ZourC7HqeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(faces)>0:                        # Calculates the number of faces\n",
        "      i=0\n",
        "      #print(faces)\n",
        "      for face in faces:\n",
        "            aligned_img = fa.align(cv2.imread(img), face['keypoints']['left_eye'], face['keypoints']['right_eye'])\n",
        "\n",
        "            print(\"Aligned face: {}, Accuracy: {:.3f}\".format(i+1, face['confidence']*100))\n",
        "            plt.imshow(aligned_img[:, :, ::-1])\n",
        "            plt.show()\n",
        "            image_name = 'image'+str(i+1)+'.jpg'\n",
        "            image_path = os.path.join('/content/Faces1',image_name)\n",
        "            cv2.imwrite(image_path,aligned_img[:, :, ::-1])\n",
        "            i+=1\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "u3lKz9jxHqp6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The matched indices are captured in list val\n",
        "faces = detect_face1(img)\n",
        "for i in val:\n",
        "  for face in faces:\n",
        "    aligned_img = fa.align(cv2.imread(img), face['keypoints']['left_eye'], face['keypoints']['right_eye'])\n",
        "    print('It is a match')\n",
        "    print(\"Aligned face: {}, Accuracy: {:.3f}\".format(i+1, face['confidence']*100))\n",
        "    plt.imshow(aligned_img[:, :, ::-1])\n",
        "    image_name = knownNames[i]\n",
        "    print(image_name)\n",
        "    cv2.imwrite(image_path,aligned_img[:, :, ::-1])\n"
      ],
      "metadata": {
        "id": "KP8sfz9ZHqud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NAmZpbAlPEAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qNNbOGwgTCSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vXO0D1NTTCUn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RQEK9DUGTCW-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install truths"
      ],
      "metadata": {
        "id": "qMIEKuxtTCcM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e729a4be-24c0-414d-d841-12cf812043af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting truths\n",
            "  Downloading truths-1.2.tar.gz (7.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from truths) (0.7.2)\n",
            "Building wheels for collected packages: truths\n",
            "  Building wheel for truths (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for truths: filename=truths-1.2-py3-none-any.whl size=7872 sha256=4b864dad43deaf7486dc133c2e6552d196212777ec5d991d28828b322fb15bfe\n",
            "  Stored in directory: /root/.cache/pip/wheels/7a/53/a8/d9a03764ba46d7fbf111a4999e7dbd5fd224be387820db3789\n",
            "Successfully built truths\n",
            "Installing collected packages: truths\n",
            "Successfully installed truths-1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from truths import Truths\n",
        "print(Truths(['a', 'b', 'x'], ['(a and b)'], ints=False))"
      ],
      "metadata": {
        "id": "TDzCeTHaTCey",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "ef7d4bb7-9a8a-42aa-83a1-74681faac1c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-77cb6dff8c5c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtruths\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTruths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTruths\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'a'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'x'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'(a and b)'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mints\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/truths/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtruths\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTruths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m: cannot import name 'Truths' from partially initialized module 'truths' (most likely due to a circular import) (/usr/local/lib/python3.10/dist-packages/truths/__init__.py)",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "waQDI3BRWzpc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}